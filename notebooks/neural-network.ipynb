{"cells": [{"metadata": {}, "cell_type": "code", "source": "# Install PyTorch, TorchVision and matplotlib\n!pip install torch==1.5.0+cpu torchvision -f https://download.pytorch.org/whl/torch_stable.html\n!pip install matplotlib", "execution_count": 1, "outputs": [{"output_type": "stream", "text": "Looking in links: https://download.pytorch.org/whl/torch_stable.html\nRequirement already satisfied: torch==1.5.0+cpu in /opt/conda/envs/Python36/lib/python3.6/site-packages (1.5.0+cpu)\nCollecting torchvision\n\u001b[?25l  Downloading https://download.pytorch.org/whl/cu92/torchvision-0.6.0%2Bcu92-cp36-cp36m-linux_x86_64.whl (6.5MB)\n\u001b[K     |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 6.5MB 1.7MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: future in /opt/conda/envs/Python36/lib/python3.6/site-packages (from torch==1.5.0+cpu) (0.17.1)\nRequirement already satisfied: numpy in /opt/conda/envs/Python36/lib/python3.6/site-packages (from torch==1.5.0+cpu) (1.15.4)\nRequirement already satisfied: pillow>=4.1.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from torchvision) (5.4.1)\nInstalling collected packages: torchvision\nSuccessfully installed torchvision-0.6.0+cu92\nRequirement already satisfied: matplotlib in /opt/conda/envs/Python36/lib/python3.6/site-packages (3.0.2)\nRequirement already satisfied: numpy>=1.10.0 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from matplotlib) (1.15.4)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from matplotlib) (0.10.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from matplotlib) (1.0.1)\nRequirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from matplotlib) (2.3.1)\nRequirement already satisfied: python-dateutil>=2.1 in /opt/conda/envs/Python36/lib/python3.6/site-packages (from matplotlib) (2.7.5)\nRequirement already satisfied: six in /opt/conda/envs/Python36/lib/python3.6/site-packages (from cycler>=0.10->matplotlib) (1.12.0)\nRequirement already satisfied: setuptools in /opt/conda/envs/Python36/lib/python3.6/site-packages (from kiwisolver>=1.0.1->matplotlib) (40.8.0)\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "import matplotlib.pyplot as plt\nimport numpy as np\nimport torch\nimport torchvision\nfrom torchvision import transforms\nimport torch.nn as nn\nimport torch.nn.functional as F", "execution_count": 2, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Build a Neural Network"}, {"metadata": {}, "cell_type": "markdown", "source": "### Build Your Own Neural Network"}, {"metadata": {}, "cell_type": "markdown", "source": "#### Load data"}, {"metadata": {}, "cell_type": "code", "source": "transform = transforms.Compose(\n    [transforms.ToTensor(),\n     transforms.Normalize((0.5,), (0.5,))])\ntrain_set = torchvision.datasets.MNIST('.', train=True, transform=transform, download=True)\ntrain_loader = torch.utils.data.DataLoader(train_set, batch_size=4, shuffle=True, num_workers=4)\ntest_set = torchvision.datasets.MNIST('.', train=False, transform=transform, download=True)\ntest_loader = torch.utils.data.DataLoader(test_set, batch_size=4, shuffle=False, num_workers=4)", "execution_count": 3, "outputs": [{"output_type": "stream", "text": "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n", "name": "stdout"}, {"output_type": "display_data", "data": {"text/plain": "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "5d0c6b6baf944028b8386f124c69f7be"}}, "metadata": {}}, {"output_type": "stream", "text": "\nExtracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n", "name": "stdout"}, {"output_type": "display_data", "data": {"text/plain": "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "6b70c4396c8d47e5bcd5ccbe5746eba2"}}, "metadata": {}}, {"output_type": "stream", "text": "\nExtracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n", "name": "stdout"}, {"output_type": "display_data", "data": {"text/plain": "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "cf9b53586b6048ff815a3f44621c1192"}}, "metadata": {}}, {"output_type": "stream", "text": "\nExtracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n", "name": "stdout"}, {"output_type": "display_data", "data": {"text/plain": "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "578ed13030934c1383be323164645ab9"}}, "metadata": {}}, {"output_type": "stream", "text": "\nExtracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\nProcessing...\nDone!\n", "name": "stdout"}, {"output_type": "stream", "text": "/pytorch/torch/csrc/utils/tensor_numpy.cpp:141: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program.\n", "name": "stderr"}]}, {"metadata": {}, "cell_type": "markdown", "source": "Display data"}, {"metadata": {}, "cell_type": "code", "source": "def imshow(img):\n    img = img / 2 + 0.5     # unnormalize\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()\n\nimages, labels = next(iter(test_loader))  # First group of test examples\nimshow(torchvision.utils.make_grid(images))\nprint('Labels:', labels)", "execution_count": 4, "outputs": [{"output_type": "display_data", "data": {"text/plain": "<Figure size 432x288 with 1 Axes>", "image/png": "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\n"}, "metadata": {"needs_background": "light"}}, {"output_type": "stream", "text": "Labels: tensor([7, 2, 1, 0])\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "### Create the Net"}, {"metadata": {}, "cell_type": "code", "source": "class MyConvNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 2, 5)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(2, 6, 5)\n        self.fc1 = nn.Linear(96, 32)\n        self.fc2 = nn.Linear(32, 10)\n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = x.view(-1, 96)\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return x\n    \nnet = MyConvNet()", "execution_count": 5, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Train"}, {"metadata": {}, "cell_type": "code", "source": "import torch.optim as optim\n\n# Define loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)", "execution_count": 6, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "for epoch in range(3):  # loop over the dataset multiple times\n\n    running_loss = 0.0\n    for i, data in enumerate(train_loader, 0):\n        # get the inputs; data is a list of [inputs, labels]\n        inputs, labels = data\n\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward\n        outputs = net(inputs)\n        loss = criterion(outputs, labels)\n        # backward (differentiate)\n        loss.backward()\n        # optimize (update)\n        optimizer.step()\n\n        # print statistics\n        running_loss += loss.item()\n        if i % 3000 == 2999:    # print every 3000 mini-batches\n            print(f'Epoch: {epoch + 1}, Iteration: {i + 1}, loss: {running_loss / 3000}')\n            running_loss = 0.0\n\n    # Test accuracy\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for data in test_loader:\n            images, labels = data\n            outputs = net(images)\n            _, predicted = torch.max(outputs.data, 1)  # The label with the maximum probability is predicted\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    print(f'Accuracy of the network on the test images: {(100 * correct / total)} %')", "execution_count": 7, "outputs": [{"output_type": "stream", "text": "Epoch: 1, Iteration: 3000, loss: 0.9212579760189789\nEpoch: 1, Iteration: 6000, loss: 0.22827606400537964\nEpoch: 1, Iteration: 9000, loss: 0.149876085664775\nEpoch: 1, Iteration: 12000, loss: 0.12869957231781426\nEpoch: 1, Iteration: 15000, loss: 0.1350821195411613\nAccuracy of the network on the test images: 95.63 %\nEpoch: 2, Iteration: 3000, loss: 0.10741373933895436\nEpoch: 2, Iteration: 6000, loss: 0.10261403205692007\nEpoch: 2, Iteration: 9000, loss: 0.10322921551451918\nEpoch: 2, Iteration: 12000, loss: 0.09648825815404401\nEpoch: 2, Iteration: 15000, loss: 0.10255164598559668\nAccuracy of the network on the test images: 96.81 %\nEpoch: 3, Iteration: 3000, loss: 0.0825312990617122\nEpoch: 3, Iteration: 6000, loss: 0.08366553215320596\nEpoch: 3, Iteration: 9000, loss: 0.08450001997421684\nEpoch: 3, Iteration: 12000, loss: 0.09115066403990378\nEpoch: 3, Iteration: 15000, loss: 0.07939330021057647\nAccuracy of the network on the test images: 97.8 %\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "### Display Sample Test Results"}, {"metadata": {}, "cell_type": "code", "source": "images, labels = next(iter(test_loader))  # First group of test examples\nimshow(torchvision.utils.make_grid(images))\nprint('Labels:', labels)\noutputs = net(images)\n_, predicted = torch.max(outputs.data, 1)  # The label with the maximum probability is predicted\nprint('Predicted:', predicted)", "execution_count": 9, "outputs": [{"output_type": "display_data", "data": {"text/plain": "<Figure size 432x288 with 1 Axes>", "image/png": "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\n"}, "metadata": {"needs_background": "light"}}, {"output_type": "stream", "text": "Labels: tensor([7, 2, 1, 0])\nPredicted: tensor([7, 2, 1, 0])\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Save Model"}, {"metadata": {}, "cell_type": "code", "source": "torch.save(net.state_dict(), 'minst-classifier.pt')", "execution_count": 10, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.6", "language": "python"}, "language_info": {"name": "python", "version": "3.6.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}